{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b3dbba8-df90-45e8-97ab-fb12a77826e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "import json\n",
    "\n",
    "# Event Hub configuration\n",
    "\n",
    "# Getting secret value from Key Vault\n",
    "eventhub_connection_string = dbutils.secrets.get(scope=\"key-vault-secretscope\", key=\"eventhub-connection-string\")\n",
    "\n",
    "EVENT_HUB_NAME = \"weatherstreamingeventhub\"\n",
    "\n",
    "# Initialize the Event Hub producer\n",
    "producer = EventHubProducerClient.from_connection_string(conn_str=eventhub_connection_string, eventhub_name=EVENT_HUB_NAME)\n",
    "\n",
    "# Function to send events to Event Hub\n",
    "def send_event(event):\n",
    "    event_data_batch = producer.create_batch()\n",
    "    event_data_batch.add(EventData(json.dumps(event)))\n",
    "    producer.send_batch(event_data_batch)\n",
    "\n",
    "# Sample JSON event\n",
    "event = {\n",
    "    \"event_id\": 2222,\n",
    "    \"event_name\": \"Key Vault Test\",\n",
    "}\n",
    "\n",
    "# Send the event\n",
    "send_event(event)\n",
    "\n",
    "# Close the producer\n",
    "producer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e041a67b-7a97-4376-a39a-f9a3709fda9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "API Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74f6f687-69b9-4478-8f7d-bff4a95cf386",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Weather:\n{\n   \"location\": {\n      \"name\": \"Los Angeles\",\n      \"region\": \"California\",\n      \"country\": \"United States of America\",\n      \"lat\": 34.0522,\n      \"lon\": -118.2428,\n      \"tz_id\": \"America/Los_Angeles\",\n      \"localtime_epoch\": 1742361265,\n      \"localtime\": \"2025-03-18 22:14\"\n   },\n   \"current\": {\n      \"last_updated_epoch\": 1742360400,\n      \"last_updated\": \"2025-03-18 22:00\",\n      \"temp_c\": 13.9,\n      \"temp_f\": 57.0,\n      \"is_day\": 0,\n      \"condition\": {\n         \"text\": \"Clear\",\n         \"icon\": \"//cdn.weatherapi.com/weather/64x64/night/113.png\",\n         \"code\": 1000\n      },\n      \"wind_mph\": 4.0,\n      \"wind_kph\": 6.5,\n      \"wind_degree\": 102,\n      \"wind_dir\": \"ESE\",\n      \"pressure_mb\": 1025.0,\n      \"pressure_in\": 30.27,\n      \"precip_mm\": 0.0,\n      \"precip_in\": 0.0,\n      \"humidity\": 72,\n      \"cloud\": 0,\n      \"feelslike_c\": 13.9,\n      \"feelslike_f\": 56.9,\n      \"windchill_c\": 13.4,\n      \"windchill_f\": 56.1,\n      \"heatindex_c\": 13.9,\n      \"heatindex_f\": 57.0,\n      \"dewpoint_c\": 6.5,\n      \"dewpoint_f\": 43.6,\n      \"vis_km\": 16.0,\n      \"vis_miles\": 9.0,\n      \"uv\": 0.0,\n      \"gust_mph\": 5.5,\n      \"gust_kph\": 8.8\n   }\n}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Getting secret value from Key Vault\n",
    "weatherapikey = dbutils.secrets.get(scope=\"key-vault-secretscope\", key=\"weatherapikey\")\n",
    "location = \"Los Angeles\"  # You can replace with city name based on your preference\n",
    "\n",
    "base_url = \"http://api.weatherapi.com/v1/\"\n",
    "\n",
    "current_weather_url = f\"{base_url}/current.json\"\n",
    "\n",
    "params = {\n",
    "    'key': weatherapikey,\n",
    "    'q': location,\n",
    "}\n",
    "response = requests.get(current_weather_url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    current_weather = response.json()\n",
    "    print(\"Current Weather:\")\n",
    "    print(json.dumps(current_weather, indent=3))\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8aace1ae-5037-493f-91c9-d4472839e361",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Complete code for getting weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea2f8c54-586b-406a-96ca-0fd0fc4ee885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Data: {\n   \"name\": \"Los Angeles\",\n   \"region\": \"California\",\n   \"country\": \"United States of America\",\n   \"lat\": 34.0522,\n   \"lon\": -118.2428,\n   \"localtime\": \"2025-03-18 22:18\",\n   \"temp_c\": 15.6,\n   \"is_day\": 0,\n   \"condition_text\": \"Clear\",\n   \"condition_icon\": \"//cdn.weatherapi.com/weather/64x64/night/113.png\",\n   \"wind_kph\": 6.5,\n   \"wind_degree\": 102,\n   \"wind_dir\": \"ESE\",\n   \"pressure_in\": 30.27,\n   \"precip_in\": 0.0,\n   \"humidity\": 32,\n   \"cloud\": 0,\n   \"feelslike_c\": 15.6,\n   \"uv\": 0.0,\n   \"air_quality\": {\n      \"co\": 506.9,\n      \"no2\": 109.335,\n      \"o3\": 6.0,\n      \"so2\": 13.135,\n      \"pm2_5\": 32.005,\n      \"pm10\": 39.405,\n      \"us-epa-index\": 2,\n      \"gb-defra-index\": 3\n   },\n   \"alerts\": [\n      {\n         \"headline\": \"High Surf Advisory issued March 18 at 3:41AM PDT until March 19 at 3:00AM PDT by NWS Los Angeles/Oxnard CA\",\n         \"severity\": \"Minor\",\n         \"description\": \"* WHAT...Large breaking waves of 6 to 9 feet with dangerous rip\\ncurrents.\\n\\n* WHERE...Ventura County Beaches.\\n\\n* WHEN...Until 3 AM PDT Wednesday.\\n\\n* IMPACTS...There is an increased risk for ocean drowning. Rip\\ncurrents can pull swimmers and surfers out to sea. Large\\nbreaking waves can cause injury, wash people off beaches and\\nrocks, and capsize small boats near shore.\\n\",\n         \"instruction\": \"Remain out of the water due to dangerous surf conditions, or stay\\nnear occupied lifeguard towers. Rock jetties can be deadly\\nlocations in such conditions, so stay off the rocks.\"\n      },\n      {\n         \"headline\": \"High Surf Advisory issued March 18 at 3:41AM PDT until March 19 at 3:00AM PDT by NWS Los Angeles/Oxnard CA\",\n         \"severity\": \"Minor\",\n         \"description\": \"* WHAT...Large breaking waves of 6 to 9 feet with dangerous rip\\ncurrents.\\n\\n* WHERE...Ventura County Beaches.\\n\\n* WHEN...Until 3 AM PDT Wednesday.\\n\\n* IMPACTS...There is an increased risk for ocean drowning. Rip\\ncurrents can pull swimmers and surfers out to sea. Large\\nbreaking waves can cause injury, wash people off beaches and\\nrocks, and capsize small boats near shore.\\n\",\n         \"instruction\": \"Remain out of the water due to dangerous surf conditions, or stay\\nnear occupied lifeguard towers. Rock jetties can be deadly\\nlocations in such conditions, so stay off the rocks.\"\n      },\n      {\n         \"headline\": \"High Surf Advisory issued March 18 at 3:41AM PDT until March 19 at 3:00AM PDT by NWS Los Angeles/Oxnard CA\",\n         \"severity\": \"Minor\",\n         \"description\": \"* WHAT...Large breaking waves of 6 to 9 feet with dangerous rip\\ncurrents.\\n\\n* WHERE...Ventura County Beaches.\\n\\n* WHEN...Until 3 AM PDT Wednesday.\\n\\n* IMPACTS...There is an increased risk for ocean drowning. Rip\\ncurrents can pull swimmers and surfers out to sea. Large\\nbreaking waves can cause injury, wash people off beaches and\\nrocks, and capsize small boats near shore.\\n\",\n         \"instruction\": \"Remain out of the water due to dangerous surf conditions, or stay\\nnear occupied lifeguard towers. Rock jetties can be deadly\\nlocations in such conditions, so stay off the rocks.\"\n      }\n   ],\n   \"forecast\": [\n      {\n         \"date\": \"2025-03-18\",\n         \"maxtemp_c\": 22.5,\n         \"mintemp_c\": 7.8,\n         \"condition\": \"Sunny\"\n      },\n      {\n         \"date\": \"2025-03-19\",\n         \"maxtemp_c\": 25.1,\n         \"mintemp_c\": 9.4,\n         \"condition\": \"Sunny\"\n      },\n      {\n         \"date\": \"2025-03-20\",\n         \"maxtemp_c\": 21.9,\n         \"mintemp_c\": 11.9,\n         \"condition\": \"Sunny\"\n      }\n   ]\n}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Function to handle the API response\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "# Function to get current weather and air quality data\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    current_weather_url = f\"{base_url}/current.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"aqi\": 'yes'\n",
    "    }\n",
    "    response = requests.get(current_weather_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Forecast Data\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    forecast_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"q\": location,\n",
    "        \"days\": days,\n",
    "    }\n",
    "    response = requests.get(forecast_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Alerts\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    alerts_url = f\"{base_url}/alerts.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"alerts\": 'yes'\n",
    "    }\n",
    "    response = requests.get(alerts_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Flatten and merge the data\n",
    "def flatten_data(current_weather, forecast_weather, alerts):\n",
    "    location_data = current_weather.get(\"location\", {})\n",
    "    current = current_weather.get(\"current\", {})\n",
    "    condition = current.get(\"condition\", {})\n",
    "    air_quality = current.get(\"air_quality\", {})\n",
    "    forecast = forecast_weather.get(\"forecast\", {}).get(\"forecastday\", [])\n",
    "    alert_list = alerts.get(\"alerts\", {}).get(\"alert\", [])\n",
    "\n",
    "    flattened_data = {\n",
    "        'name': location_data.get('name'),\n",
    "        'region': location_data.get('region'),\n",
    "        'country': location_data.get('country'),\n",
    "        'lat': location_data.get('lat'),\n",
    "        'lon': location_data.get('lon'),\n",
    "        'localtime': location_data.get('localtime'),\n",
    "        'temp_c': current.get('temp_c'),\n",
    "        'is_day': current.get('is_day'),\n",
    "        'condition_text': condition.get('text'),\n",
    "        'condition_icon': condition.get('icon'),\n",
    "        'wind_kph': current.get('wind_kph'),\n",
    "        'wind_degree': current.get('wind_degree'),\n",
    "        'wind_dir': current.get('wind_dir'),\n",
    "        'pressure_in': current.get('pressure_in'),\n",
    "        'precip_in': current.get('precip_in'),\n",
    "        'humidity': current.get('humidity'),\n",
    "        'cloud': current.get('cloud'),\n",
    "        'feelslike_c': current.get('feelslike_c'),\n",
    "        'uv': current.get('uv'),\n",
    "        'air_quality': {\n",
    "            'co': air_quality.get('co'),\n",
    "            'no2': air_quality.get('no2'),\n",
    "            'o3': air_quality.get('o3'),\n",
    "            'so2': air_quality.get('so2'),\n",
    "            'pm2_5': air_quality.get('pm2_5'),\n",
    "            'pm10': air_quality.get('pm10'),\n",
    "            'us-epa-index': air_quality.get('us-epa-index'),\n",
    "            'gb-defra-index': air_quality.get('gb-defra-index')\n",
    "        },\n",
    "        'alerts': [\n",
    "            {\n",
    "                'headline': alert.get('headline'),\n",
    "                'severity': alert.get('severity'),\n",
    "                'description': alert.get('desc'),\n",
    "                'instruction': alert.get('instruction')\n",
    "            }\n",
    "            for alert in alert_list\n",
    "        ],\n",
    "        'forecast': [\n",
    "            {\n",
    "                'date': day.get('date'),\n",
    "                'maxtemp_c': day.get('day', {}).get('maxtemp_c'),\n",
    "                'mintemp_c': day.get('day', {}).get('mintemp_c'),\n",
    "                'condition': day.get('day', {}).get('condition', {}).get('text')\n",
    "            }\n",
    "            for day in forecast\n",
    "        ]\n",
    "    }\n",
    "    return flattened_data\n",
    "\n",
    "# Main program\n",
    "def fetch_weather_data():\n",
    "\n",
    "    base_url = \"http://api.weatherapi.com/v1/\"\n",
    "    location = \"Los Angeles\"  # You can replace with any city name based on your preference\n",
    "    weatherapikey = dbutils.secrets.get(scope=\"key-vault-secretscope\", key=\"weatherapikey\")\n",
    "\n",
    "    # Get data from API\n",
    "    current_weather = get_current_weather(base_url, weatherapikey, location)\n",
    "    forecast_weather = get_forecast_weather(base_url, weatherapikey, location, 3)\n",
    "    alerts = get_alerts(base_url, weatherapikey, location)\n",
    "\n",
    "    # Flatten and merge data\n",
    "    merged_data = flatten_data(current_weather, forecast_weather, alerts)\n",
    "    print(\"Weather Data:\", json.dumps(merged_data, indent=3))\n",
    "\n",
    "# Calling the Main Program\n",
    "fetch_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ff3e361-d55b-4d56-8994-0a28e65f1a57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Sending the complete weather data to Event Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edd0983b-c7ee-4781-8f5f-9b16e6312959",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "\n",
    "# Event Hub configuration\n",
    "\n",
    "# Getting secret value from Key Vault\n",
    "eventhub_connection_string = dbutils.secrets.get(scope=\"key-vault-secretscope\", key=\"eventhub-connection-string\")\n",
    "\n",
    "EVENT_HUB_NAME = \"weatherstreamingeventhub\"\n",
    "\n",
    "# Initialize the Event Hub producer\n",
    "producer = EventHubProducerClient.from_connection_string(conn_str=eventhub_connection_string, eventhub_name=EVENT_HUB_NAME)\n",
    "\n",
    "# Function to send events to Event Hub\n",
    "def send_event(event):\n",
    "    event_data_batch = producer.create_batch()\n",
    "    event_data_batch.add(EventData(json.dumps(event)))\n",
    "    producer.send_batch(event_data_batch)\n",
    "\n",
    "# Function to handle the API response\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "# Function to get current weather and air quality data\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    current_weather_url = f\"{base_url}/current.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"aqi\": 'yes'\n",
    "    }\n",
    "    response = requests.get(current_weather_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Forecast Data\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    forecast_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"q\": location,\n",
    "        \"days\": days,\n",
    "    }\n",
    "    response = requests.get(forecast_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Alerts\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    alerts_url = f\"{base_url}/alerts.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"alerts\": 'yes'\n",
    "    }\n",
    "    response = requests.get(alerts_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Flatten and merge the data\n",
    "def flatten_data(current_weather, forecast_weather, alerts):\n",
    "    location_data = current_weather.get(\"location\", {})\n",
    "    current = current_weather.get(\"current\", {})\n",
    "    condition = current.get(\"condition\", {})\n",
    "    air_quality = current.get(\"air_quality\", {})\n",
    "    forecast = forecast_weather.get(\"forecast\", {}).get(\"forecastday\", [])\n",
    "    alert_list = alerts.get(\"alerts\", {}).get(\"alert\", [])\n",
    "\n",
    "    flattened_data = {\n",
    "        'name': location_data.get('name'),\n",
    "        'region': location_data.get('region'),\n",
    "        'country': location_data.get('country'),\n",
    "        'lat': location_data.get('lat'),\n",
    "        'lon': location_data.get('lon'),\n",
    "        'localtime': location_data.get('localtime'),\n",
    "        'temp_c': current.get('temp_c'),\n",
    "        'is_day': current.get('is_day'),\n",
    "        'condition_text': condition.get('text'),\n",
    "        'condition_icon': condition.get('icon'),\n",
    "        'wind_kph': current.get('wind_kph'),\n",
    "        'wind_degree': current.get('wind_degree'),\n",
    "        'wind_dir': current.get('wind_dir'),\n",
    "        'pressure_in': current.get('pressure_in'),\n",
    "        'precip_in': current.get('precip_in'),\n",
    "        'humidity': current.get('humidity'),\n",
    "        'cloud': current.get('cloud'),\n",
    "        'feelslike_c': current.get('feelslike_c'),\n",
    "        'uv': current.get('uv'),\n",
    "        'air_quality': {\n",
    "            'co': air_quality.get('co'),\n",
    "            'no2': air_quality.get('no2'),\n",
    "            'o3': air_quality.get('o3'),\n",
    "            'so2': air_quality.get('so2'),\n",
    "            'pm2_5': air_quality.get('pm2_5'),\n",
    "            'pm10': air_quality.get('pm10'),\n",
    "            'us-epa-index': air_quality.get('us-epa-index'),\n",
    "            'gb-defra-index': air_quality.get('gb-defra-index')\n",
    "        },\n",
    "        'alerts': [\n",
    "            {\n",
    "                'headline': alert.get('headline'),\n",
    "                'severity': alert.get('severity'),\n",
    "                'description': alert.get('desc'),\n",
    "                'instruction': alert.get('instruction')\n",
    "            }\n",
    "            for alert in alert_list\n",
    "        ],\n",
    "        'forecast': [\n",
    "            {\n",
    "                'date': day.get('date'),\n",
    "                'maxtemp_c': day.get('day', {}).get('maxtemp_c'),\n",
    "                'mintemp_c': day.get('day', {}).get('mintemp_c'),\n",
    "                'condition': day.get('day', {}).get('condition', {}).get('text')\n",
    "            }\n",
    "            for day in forecast\n",
    "        ]\n",
    "    }\n",
    "    return flattened_data\n",
    "\n",
    "# Main program\n",
    "def fetch_weather_data():\n",
    "\n",
    "    base_url = \"http://api.weatherapi.com/v1/\"\n",
    "    location = \"Los Angeles\"  # You can replace with any city name based on your preference\n",
    "    weatherapikey = dbutils.secrets.get(scope=\"key-vault-secretscope\", key=\"weatherapikey\")\n",
    "\n",
    "    # Get data from API\n",
    "    current_weather = get_current_weather(base_url, weatherapikey, location)\n",
    "    forecast_weather = get_forecast_weather(base_url, weatherapikey, location, 3)\n",
    "    alerts = get_alerts(base_url, weatherapikey, location)\n",
    "\n",
    "    # Flatten and merge data\n",
    "    merged_data = flatten_data(current_weather, forecast_weather, alerts)\n",
    "\n",
    "    # Sending the weather data to Event HUB\n",
    "    send_event(merged_data)\n",
    "    \n",
    "\n",
    "# Calling the Main Program\n",
    "fetch_weather_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d4fba93-307c-4f84-83e3-65b6615dd2ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sending the weather data in streaming fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f2747cf-aa3e-4779-b415-1d1d450951a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:728)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:446)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:446)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:464)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:571)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:51)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:51)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:51)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:51)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:553)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:846)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:872)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:871)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:926)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:719)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:545)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:48)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:545)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:523)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:175)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:728)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:446)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:446)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:464)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:571)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:51)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:51)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:51)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:51)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:553)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:846)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:872)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:871)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:926)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:719)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:545)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:48)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:545)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:523)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:175)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Event Hub configuration\n",
    "EVENT_HUB_NAME = \"weatherstreamingeventhub\"\n",
    "eventhub_connection_string = dbutils.secrets.get(scope=\"key-vault-secretscope\", key=\"eventhub-connection-string\")\n",
    "weatherapikey = dbutils.secrets.get(scope=\"key-vault-secretscope\", key=\"weatherapikey\")\n",
    "\n",
    "# Initialize the Event Hub producer\n",
    "producer = EventHubProducerClient.from_connection_string(conn_str=eventhub_connection_string, eventhub_name=EVENT_HUB_NAME)\n",
    "\n",
    "# Function to send events to Event Hub\n",
    "def send_event(event):\n",
    "    event_data_batch = producer.create_batch()\n",
    "    event_data_batch.add(EventData(json.dumps(event)))\n",
    "    producer.send_batch(event_data_batch)\n",
    "\n",
    "# Function to handle the API response\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "# Function to get current weather and air quality data\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    current_weather_url = f\"{base_url}/current.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"aqi\": 'yes'\n",
    "    }\n",
    "    response = requests.get(current_weather_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Forecast Data\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    forecast_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"q\": location,\n",
    "        \"days\": days,\n",
    "    }\n",
    "    response = requests.get(forecast_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Alerts\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    alerts_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"alerts\": 'yes'\n",
    "    }\n",
    "    response = requests.get(alerts_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Flatten and merge the data\n",
    "def flatten_data(current_weather, forecast_weather, alerts):\n",
    "    location_data = current_weather.get(\"location\", {})\n",
    "    current = current_weather.get(\"current\", {})\n",
    "    condition = current.get(\"condition\", {})\n",
    "    air_quality = current.get(\"air_quality\", {})\n",
    "    forecast = forecast_weather.get(\"forecast\", {}).get(\"forecastday\", [])\n",
    "    alert_list = alerts.get(\"alerts\", {}).get(\"alert\", [])\n",
    "\n",
    "    flattened_data = {\n",
    "        'name': location_data.get('name'),\n",
    "        'region': location_data.get('region'),\n",
    "        'country': location_data.get('country'),\n",
    "        'lat': location_data.get('lat'),\n",
    "        'lon': location_data.get('lon'),\n",
    "        'localtime': location_data.get('localtime'),\n",
    "        'temp_c': current.get('temp_c'),\n",
    "        'is_day': current.get('is_day'),\n",
    "        'condition_text': condition.get('text'),\n",
    "        'condition_icon': condition.get('icon'),\n",
    "        'wind_kph': current.get('wind_kph'),\n",
    "        'wind_degree': current.get('wind_degree'),\n",
    "        'wind_dir': current.get('wind_dir'),\n",
    "        'pressure_in': current.get('pressure_in'),\n",
    "        'precip_in': current.get('precip_in'),\n",
    "        'humidity': current.get('humidity'),\n",
    "        'cloud': current.get('cloud'),\n",
    "        'feelslike_c': current.get('feelslike_c'),\n",
    "        'uv': current.get('uv'),\n",
    "        'air_quality': {\n",
    "            'co': air_quality.get('co'),\n",
    "            'no2': air_quality.get('no2'),\n",
    "            'o3': air_quality.get('o3'),\n",
    "            'so2': air_quality.get('so2'),\n",
    "            'pm2_5': air_quality.get('pm2_5'),\n",
    "            'pm10': air_quality.get('pm10'),\n",
    "            'us-epa-index': air_quality.get('us-epa-index'),\n",
    "            'gb-defra-index': air_quality.get('gb-defra-index')\n",
    "        },\n",
    "        'alerts': [\n",
    "            {\n",
    "                'headline': alert.get('headline'),\n",
    "                'severity': alert.get('severity'),\n",
    "                'description': alert.get('desc'),\n",
    "                'instruction': alert.get('instruction')\n",
    "            }\n",
    "            for alert in alert_list\n",
    "        ],\n",
    "        'forecast': [\n",
    "            {\n",
    "                'date': day.get('date'),\n",
    "                'maxtemp_c': day.get('day', {}).get('maxtemp_c'),\n",
    "                'mintemp_c': day.get('day', {}).get('mintemp_c'),\n",
    "                'condition': day.get('day', {}).get('condition', {}).get('text')\n",
    "            }\n",
    "            for day in forecast\n",
    "        ]\n",
    "    }\n",
    "    return flattened_data\n",
    "\n",
    "\n",
    "def fetch_weather_data():\n",
    "\n",
    "    base_url = \"http://api.weatherapi.com/v1/\"\n",
    "    location = \"Los Angeles\" # You can replace with any city name based on your preference\n",
    "    weatherapikey = dbutils.secrets.get(scope=\"key-vault-secretscope\", key=\"weatherapikey\")\n",
    "\n",
    "    # Get data from API\n",
    "    current_weather = get_current_weather(base_url, weatherapikey, location)\n",
    "    forecast_weather = get_forecast_weather(base_url, weatherapikey, location, 3)\n",
    "    alerts = get_alerts(base_url, weatherapikey, location)\n",
    "\n",
    "    # Flatten and merge data\n",
    "    merged_data = flatten_data(current_weather, forecast_weather, alerts)\n",
    "    return merged_data\n",
    "\n",
    "# Main program\n",
    "def process_batch(batch_df, batch_id):\n",
    "    try:     \n",
    "        # Fetch weather data\n",
    "        weather_data = fetch_weather_data()\n",
    "        \n",
    "        # Send the weather data (current weather part)\n",
    "        send_event(weather_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending events in batch {batch_id}: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "# Set up a streaming source (for example, rate source for testing purposes)\n",
    "streaming_df = spark.readStream.format(\"rate\").option(\"rowsPerSecond\", 1).load()\n",
    "\n",
    "# Write the streaming data using foreachBatch to send weather data to Event Hub\n",
    "query = streaming_df.writeStream.foreachBatch(process_batch).start()\n",
    "\n",
    "query.awaitTermination()\n",
    "\n",
    "# Close the producer after termination\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c986d36-01d1-4b6a-973b-895007504099",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sending the weather data every 30 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf1c6bc3-c818-4793-9d18-2628ed00387c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event Sent at 2025-03-19 06:46:17.712557\nEvent Sent at 2025-03-19 06:46:48.005665\nEvent Sent at 2025-03-19 06:47:18.976677\nEvent Sent at 2025-03-19 06:47:49.950702\nEvent Sent at 2025-03-19 06:48:20.911350\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:728)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:446)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:446)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:464)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:571)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:51)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:51)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:51)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:51)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:553)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:846)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:872)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:871)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:926)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:719)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:545)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:48)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:545)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:523)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:175)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:728)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:446)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:446)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:464)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:571)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:51)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:51)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:51)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:51)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:553)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:846)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:872)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:871)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:926)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:719)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:545)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:48)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:545)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:523)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:175)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Event Hub configuration\n",
    "EVENT_HUB_NAME = \"weatherstreamingeventhub\"\n",
    "eventhub_connection_string = dbutils.secrets.get(scope=\"key-vault-secretscope\", key=\"eventhub-connection-string\")\n",
    "weatherapikey = dbutils.secrets.get(scope=\"key-vault-secretscope\", key=\"weatherapikey\")\n",
    "\n",
    "# Initialize the Event Hub producer\n",
    "producer = EventHubProducerClient.from_connection_string(conn_str=eventhub_connection_string, eventhub_name=EVENT_HUB_NAME)\n",
    "\n",
    "# Function to send events to Event Hub\n",
    "def send_event(event):\n",
    "    event_data_batch = producer.create_batch()\n",
    "    event_data_batch.add(EventData(json.dumps(event)))\n",
    "    producer.send_batch(event_data_batch)\n",
    "\n",
    "# Function to handle the API response\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "# Function to get current weather and air quality data\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    current_weather_url = f\"{base_url}/current.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"aqi\": 'yes'\n",
    "    }\n",
    "    response = requests.get(current_weather_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Forecast Data\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    forecast_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"q\": location,\n",
    "        \"days\": days,\n",
    "    }\n",
    "    response = requests.get(forecast_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Alerts\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    alerts_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"alerts\": 'yes'\n",
    "    }\n",
    "    response = requests.get(alerts_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Flatten and merge the data\n",
    "def flatten_data(current_weather, forecast_weather, alerts):\n",
    "    location_data = current_weather.get(\"location\", {})\n",
    "    current = current_weather.get(\"current\", {})\n",
    "    condition = current.get(\"condition\", {})\n",
    "    air_quality = current.get(\"air_quality\", {})\n",
    "    forecast = forecast_weather.get(\"forecast\", {}).get(\"forecastday\", [])\n",
    "    alert_list = alerts.get(\"alerts\", {}).get(\"alert\", [])\n",
    "\n",
    "    flattened_data = {\n",
    "        'name': location_data.get('name'),\n",
    "        'region': location_data.get('region'),\n",
    "        'country': location_data.get('country'),\n",
    "        'lat': location_data.get('lat'),\n",
    "        'lon': location_data.get('lon'),\n",
    "        'localtime': location_data.get('localtime'),\n",
    "        'temp_c': current.get('temp_c'),\n",
    "        'is_day': current.get('is_day'),\n",
    "        'condition_text': condition.get('text'),\n",
    "        'condition_icon': condition.get('icon'),\n",
    "        'wind_kph': current.get('wind_kph'),\n",
    "        'wind_degree': current.get('wind_degree'),\n",
    "        'wind_dir': current.get('wind_dir'),\n",
    "        'pressure_in': current.get('pressure_in'),\n",
    "        'precip_in': current.get('precip_in'),\n",
    "        'humidity': current.get('humidity'),\n",
    "        'cloud': current.get('cloud'),\n",
    "        'feelslike_c': current.get('feelslike_c'),\n",
    "        'uv': current.get('uv'),\n",
    "        'air_quality': {\n",
    "            'co': air_quality.get('co'),\n",
    "            'no2': air_quality.get('no2'),\n",
    "            'o3': air_quality.get('o3'),\n",
    "            'so2': air_quality.get('so2'),\n",
    "            'pm2_5': air_quality.get('pm2_5'),\n",
    "            'pm10': air_quality.get('pm10'),\n",
    "            'us-epa-index': air_quality.get('us-epa-index'),\n",
    "            'gb-defra-index': air_quality.get('gb-defra-index')\n",
    "        },\n",
    "        'alerts': [\n",
    "            {\n",
    "                'headline': alert.get('headline'),\n",
    "                'severity': alert.get('severity'),\n",
    "                'description': alert.get('desc'),\n",
    "                'instruction': alert.get('instruction')\n",
    "            }\n",
    "            for alert in alert_list\n",
    "        ],\n",
    "        'forecast': [\n",
    "            {\n",
    "                'date': day.get('date'),\n",
    "                'maxtemp_c': day.get('day', {}).get('maxtemp_c'),\n",
    "                'mintemp_c': day.get('day', {}).get('mintemp_c'),\n",
    "                'condition': day.get('day', {}).get('condition', {}).get('text')\n",
    "            }\n",
    "            for day in forecast\n",
    "        ]\n",
    "    }\n",
    "    return flattened_data\n",
    "\n",
    "\n",
    "def fetch_weather_data():\n",
    "\n",
    "    base_url = \"http://api.weatherapi.com/v1/\"\n",
    "    location = \"Los Angeles\"  # You can replace with any city name based on your preference\n",
    "    weatherapikey = dbutils.secrets.get(scope=\"key-vault-secretscope\", key=\"weatherapikey\")\n",
    "\n",
    "    # Get data from API\n",
    "    current_weather = get_current_weather(base_url, weatherapikey, location)\n",
    "    forecast_weather = get_forecast_weather(base_url, weatherapikey, location, 3)\n",
    "    alerts = get_alerts(base_url, weatherapikey, location)\n",
    "\n",
    "    # Flatten and merge data\n",
    "    merged_data = flatten_data(current_weather, forecast_weather, alerts)\n",
    "    return merged_data\n",
    "\n",
    "# Function to process each batch of streaming data\n",
    "last_sent_time = datetime.now() - timedelta(seconds=30)  # Initialize last sent time\n",
    "\n",
    "\n",
    "# Main program\n",
    "def process_batch(batch_df, batch_id):\n",
    "    global last_sent_time\n",
    "    try:\n",
    "        # Get current time\n",
    "        current_time = datetime.now()\n",
    "        \n",
    "        # Check if 30 seconds have passed since last event was sent\n",
    "        if (current_time - last_sent_time).total_seconds() >= 30:\n",
    "            # Fetch weather data\n",
    "            weather_data = fetch_weather_data()\n",
    "            \n",
    "            # Send the weather data (current weather part)\n",
    "            send_event(weather_data)\n",
    "\n",
    "            # Update last sent time\n",
    "            last_sent_time = current_time\n",
    "            print(f'Event Sent at {last_sent_time}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending events in batch {batch_id}: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "# Set up a streaming source (for example, rate source for testing purposes)\n",
    "streaming_df = spark.readStream.format(\"rate\").option(\"rowsPerSecond\", 1).load()\n",
    "\n",
    "# Write the streaming data using foreachBatch to send weather data to Event Hub\n",
    "query = streaming_df.writeStream.foreachBatch(process_batch).start()\n",
    "\n",
    "query.awaitTermination()\n",
    "\n",
    "# Close the producer after termination\n",
    "producer.close()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "weather-streaming-notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}